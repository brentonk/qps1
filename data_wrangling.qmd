# Data Wrangling {#sec-data-wrangling}

In @sec-intro-r, we saw how to get data into R and the basics of writing code in Quarto.
Now we're going to dig further into "wrangling" raw data into a form that's useful for analysis.

In both academic research and industry data science, the hard part of data analysis usually isn't the statistical modeling --- it's to acquire the data in the first place, and then to get it into a state that's clean enough to plug into whatever statistical model you plan to use.

The main data wrangling skills you're going to pick up here are:

1.  How to [subset the data]{.concept} to the variables (columns) and observations (rows) that you care about for your analysis.
    Along the way, you'll see how to use the most common [logical and comparison operators]{.concept} in scientific computing:
    
    *   equal to: `==`
    *   not equal to: `!=`
    *   greater than: `>`
    *   less than: `<`
    *   not: `!`
    *   and: `&`
    *   or: `|`
    
2.  Methods to [transform]{.concept} your data: changing variables in place, creating new variables, summarizing variables both for the full data and within subcategories of observations.

3.  How to [reshape]{.concept} data into "longer" and "wider" formats, which is especially important when your raw data comes to you in a weird or inconvenient shape (more often than you'd like!).

4.  How to [merge]{.concept} data sets from disparate sources together into a single data frame you can analyze.


## Data: International crises

We will work with data from the [International Crisis Behavior Project](https://sites.duke.edu/icbdata/data-collections/) on countries involved in international crises.
The project's operational definition of an international crisis is a situation in which there is

> ... (1) a change in type and/or an increase in intensity of *disruptive*, that is, hostile verbal or physical *interactions* between two or more states, with a heightened probability of *military hostilities*; that, in turn, (2) destabilizes their relationship and *challenges* the *structure* of an international system --- global, dominant, or subsystem.

::: {.aside}
Quotation from Michael Brecher and Jonathan Wilkenfeld, *A Study of Crisis*, pages 4--5.
:::

To put it more simply, countries are in a state of crisis when something happens that raises tensions between them to the point that there is a legitimate fear of war.
Every war starts as a crisis, but not all crises lead to war (and in fact the vast majority do not).

We will work with the ICB Project's "actor level" dataset, in which each observation (row) is a crisis participant.
For example, in the Cuban Missile Crisis of 1962 (crisis #196 in the ICB data), the United States, Cuba, and the Soviet Union are each separate crisis participants.
The data is on my website at <https://bkenkel.com/qps1/data/crises.csv>.

```{r}
#| message: false
library("tidyverse")
df_crises <- read_csv("https://bkenkel.com/qps1/data/crises.csv")

df_crises
```

As you can see, there are a *ton* of variables here.
The ICB Project provides [a full codebook](https://duke.box.com/s/l4glcl5jaipmycs7unzraxkp92w1nh3d) describing each variable in the dataset.
The most important variables you need to know from the start are:

*   `crisname` and `crisno`: The name of the crisis and a numeric identifier assigned to each separate crisis.

*   `actor` and `cracid`: A country involved in the crisis and a numeric identifier assigned to each different country (e.g., USA = 2, Russia/Soviet Union = 365).

*   `systrgyr`: The year the crisis began.

So for example, the first crisis in the data (`crisno` = 1) is the Russian Civil War, which only involved Russia.
The second (`crisno` = 2) is a 1918 crisis between Nicaragua and Costa Rica, each of which gets their own row in the data.

## Subsetting

### Subsetting by column: `select()`

The `select()` function lets us reduce the data frame just to have the columns we care about, or even just reorder the columns if you're not trying to get rid of any data but want things to be arranged differently.

#### Basic usage

The simplest way to use `select()` is to tell it what data frame you're working with, then list the names of the columns you want to keep from it.

```{r}
select(df_crises, crisname, actor, systrgyr)
```

An important thing to know about how R works:
Just running a function like this won't change your data frame permanently.
To see this, after running `select()` like the above, go back and look at the data frame --- nothing has changed:

```{r}
df_crises
```

All the original data is still there.
Unlike some other programming languages, R essentially never modifies data "in place".
If you want to overwrite `df_crises` with the subsetted version, you need to explicitly tell R to overwrite it by assigning the `select()`'ed data frame to `df_crises`, as in:

```{.r}
# I don't want to overwrite df_crises, so not actually running this
df_crises <- select(df_crises, crisname, actor, systrgyr)
```

Just as a matter of workflow, I usually try not to overwrite the raw data frame that I've read into R.
That way, if I decide later on that I want more out of the original data, I don't have to go back and load from the CSV file and clean it up again.
So in this case, I would typically just create a new data frame with the subsetted data:

```{r}
df_crises_reduced <- select(df_crises, crisname, actor, systrgyr)

df_crises_reduced
```

#### Selecting by range or pattern

Suppose you wanted everything from the `crisno` column through the `systrgyr` column.
Instead of typing out each column name explicitly, you can just use a colon (`:`) to tell `select()` to grab this range of variables:

```{r}
select(df_crises, crisno:systrgyr)
```

If you want everything *except* a particular variable, you can use the minus sign (`-`) to exclude it.
Let's see how to get rid of the useless `icb2` column that just marks the dataset version:

```{r}
select(df_crises, -icb2)
```

::: {.callout-note title="In-class exercise"}
What if you wanted to exclude the range of variables from `actor` through `yrtrig`?
How would you do that without typing out each column name explicitly?

```{r}
#
# [Write your answer here]
#
```
:::

You can use the `starts_with()` subfunction to select all of the columns whose name starts with "sys", for example:

```{r}
select(df_crises, starts_with("sys"))
```

::: {.callout-note title="In-class exercise"}
What happens if you instead run `select(df_crises, starts_with(sys))` (without the quotation marks around `sys`)?
Why doesn't this work?

>
> [Write your answer here]
>
:::

There are many other subfunctions you can use to select columns without naming them each explicitly.
You can learn about them by looking at the [help page]{.concept} for the `select()` function.
To see the help page for any R function, just enter `?name_of_function` at the R console, like the following:

```{.r}
?select
```

::: {.callout-note title="In-class exercise"}
Select the columns whose name has `"fav"` anywhere in it.
Look at the `?select` help page to figure out the subfunction you need to do this.

```{r}
#
# [Write your answer here]
#
```
:::

#### Reordering and renaming

As you select variables, you can rename them by using the syntax `newname = oldname`:

```{r}
select(df_crises, year = systrgyr, name = crisname)
```

To rename individual columns without dropping or rearranging the other columns, use the `rename()` function instead of `select()`.

```{r}
rename(df_crises, year = systrgyr, name = crisname)
```

If you want certain columns to be placed first, use the `relocate()` function.

```{r}
relocate(df_crises, crisname, actor)
```

To rearrange the rows of the data, you can use the `arrange()` function.
By default, it sorts the data in ascending order of the column name(s) you feed it.

```{r}
# Arrange in ascending order of actor numeric ID
arrange(df_crises, cracid)

# Arrange by start year, then by actor ID within year
arrange(df_crises, systrgyr, cracid)
```

To instead sort in descending order, wrap the variable name in `desc()`.

```{r}
# Arrange so that the most recent crises come first
arrange(df_crises, desc(systrgyr))
```

### Subsetting by row: `filter()`

What if we only want the crises that started during the Cold War?
That involves selecting rows from the data rather than columns, which we'll use the `filter()` function for.
But before we can do that, we need to learn a bit about making logical statements in R.

#### Comparisons and logical operators

If we make a **comparison** in R, it will spit out whether our statement is `TRUE` or `FALSE`.
There are six logical comparisons we can make in R:

*   `x == y`: Is `x` equal to `y`?
    (Notice that we use a double equals sign, not a single one!)
    
*   `x != y`: Is `x` unequal to `y`?

*   `x > y`: Is `x` greater than `y`?

*   `x >= y`: Is `x` greater than or equal to `y`?

*   `x < y`: Is `x` less than `y`?

*   `x <= y`: Is `x` less than or equal to `y`?

As an example, let's assign the value 1950 to the variable `x`.

```{r}
x <- 1950
```

Now let's look at the values of a few logical comparisons.

```{r}
x == 1950
x == 1951
x != 1951
x < 1950
x <= 1950
```

If we use these with a vector of numbers, R calculates the comparison for each individual element of the vector.
So instead of just looking at 1950, let's look at each number from 1948 to 1952.

```{r}
x <- 1948:1952
x
```

We've got a vector of five years here, so each of our logical comparisons will now return a vector of five `TRUE`/`FALSE` values.

```{r}
x == 1950
x == 1951
x != 1951
x < 1950
x <= 1950
```

You can combine logical comparisons like this with square brackets to select elements from a vector on the basis of a logical comparison.

```{r}
x[x < 1950]
```

Above we've compared a vector to a single number.
What if we compare a vector to another vector of the same length?

::: {.aside}
The last possibility is comparing a vector to another vector of a *different* length.
Loosely speaking, R handles this situation by repeating the shorter vector until the two match up.
R's behavior in this situation can be hard to predict, so I recommend only doing logical comparisons against either a single number, or a vector of the same length.
You can check the length of a vector using the `length()` function, FYI.
:::


```{r}
y <- c(1948, 1948, 1950, 1950, 1946)
y

x == y
x != y
x > y
x >= y
```

The exclamation point means "not".
You can use it to turn `TRUE` into `FALSE` and vice versa.
Just make sure that you put parentheses around the whole statement that you're trying to negate.

```{r}
!(x >= y)
```

Sometimes we will want to string together multiple comparisons.
There are two ways to combine comparisons.

*   [and]{.concept}: `a & b` is `TRUE` when `a` is `TRUE` and `b` is also `TRUE`.
    If either or both are `FALSE`, then so is `a & b`.
    
*   [or]{.concept}: `a | b` is `TRUE` when `a` is `TRUE`, or `b` is `TRUE`, or both.
    The only way for `a | b` to be `FALSE` is for both `a` and `b` to be FALSE.

| `a`     | `b`     | `a & b` (and) | `a | b` (or) |
|:--------|:--------|:--------------|:-------------|
| `TRUE`  | `TRUE`  | `TRUE`        | `TRUE`       |
| `TRUE`  | `FALSE` | `FALSE`       | `TRUE`       |
| `FALSE` | `TRUE`  | `FALSE`       | `TRUE`       |
| `FALSE` | `FALSE` | `FALSE`       | `FALSE`      |

```{r}
# Reminder:
# x = 1948, 1949, 1950, 1951, 1952
# y = 1948, 1948, 1950, 1950, 1946

x > y & x < 1950
x > y | x < 1950
```

Be aware that `&` and `|` only operate on `TRUE` and `FALSE` values, not on other values.
There are situations where you might use "and" or "or" in an English sentence, but where `&` and `|` can't just be substituted into your R code.
For example, think about trying to code up the logical statement "`x` or `y` is less than 100."

```{r}
x <- c(75, 100, 125, 150)
y <- c(100, 90, 150, 99)

# Won't work correctly, because x and y aren't TRUE/FALSE
(x | y) < 100

# Will work correctly, because "x < 100" and "y < 100" are TRUE/FALSE
(x < 100) | (y < 100)
```

::: {.aside}
Completely optional aside for those who are morbidly curious why we get all `TRUE` values when we run `(x | y) < 100`:
When you plug numbers into a logical operator, any non-zero number evaluates to `TRUE`.
Since every element of `x` and `y` is nonzero, `x | y` evaluates to `TRUE, TRUE, TRUE, TRUE`.
Then, when you plug logical values into a numerical comparison, `TRUE` values are treated like 1 and `FALSE` values like 0.
So R converts each `TRUE` to 1, observes that 1 is less than 100, and again returns `TRUE` for each one.
:::

One final minor note:
If you look for R help on the Internet, you'll sometimes see people use `&&` and `||`.
What's the difference between `&` and `&&`, or between `|` and `||`?
The doubled versions only work on a [single]{.underline} `TRUE`/`FALSE` statement.
This distinction is important in programming situations where you need to make sure you're only working with a single value.
That won't typically come up in this course, so to make our lives easier we'll just always use the single versions.

```{r}
#| error: true
x <- c(1, 2, 3, 4, 5)
y <- c(1, 1, 4, 4, 8)

x < y | x > y   # returns c(FALSE, TRUE, TRUE, FALSE, TRUE)
x < y || x > y  # won't run, will give error message
```

#### The `filter()` function

Now that we're familiar with comparisons and logical operators, let's return to the crisis data to reduce it down to Cold War--era observations.

Remember that we can pull a single column from a data frame using the dollar sign.
And we can use square brackets on a data frame to select particular observations from it.
So we *could* subset to the Cold War observations that way.

```{r}
df_crises[df_crises$systrgyr >= 1946 & df_crises$systrgyr <= 1989, ]
```

That works, but it's a bit ugly and unwieldy.
The `filter()` function gives us an easier way to do the same thing.

```{r}
filter(df_crises, systrgyr >= 1946 & systrgyr <= 1989)
```

When dealing with character columns, the greater/lesser comparisons no longer make sense, but we can still use the equality and inequality comparisons.
Just make sure to use quotation marks around whatever you're comparing to!

```{r}
filter(df_crises, actor == "USA")
filter(df_crises, actor != "RUS")
```

What if you wanted to get all of the observations involving the United States (USA), Russia (RUS), or the United Kingdom (UKG)?
One kind of tedious way to go about it would be to string many "or" statements together.

```{r}
filter(df_crises, actor == "USA" | actor == "RUS" | actor == "UKG")
```

The easier way --- especially if you're matching a large number of values --- is to use the `%in%` operator in R.
When you run `x %in% y`, it gives you a `TRUE` or `FALSE` for each entry of `x`: `TRUE` if it matches at least one entry of `y`, and `FALSE` otherwise.

```{r}
filter(df_crises, actor %in% c("USA", "RUS", "UKG"))
```

::: {.callout-note title="In-class exercise"}
How can you filter down to the observations that are *not* those three countries?

```{r}
#
# [Write your answer here]
#
```
:::

### "Piping" commands together

Here's a pretty common way to start off your data analysis workflow:

1.  Load your raw data into R.
2.  Reduce the columns down to the ones you will use in your analysis.
3.  Filter out the rows that aren't relevant to your analysis.

Remember that R doesn't save what you do to a data frame unless you explicitly assign the result to a variable.
This means that a data cleaning process might involve a lot of intermediate assignments that you never end up using again.

Imagine we want to extract the name of the crisis, the name and numeric ID of the country involved, the year the crisis began, the number of days it lasted (`trgterra`), and the outcome for the given actor (`outcom`)
Along the way we'll rename the variables to be less ugly.
And furthermore imagine we only want Cold War--era observations, and only for the USA, Russia, and the United Kingdom.
We could run the following sequence of commands:

```{r}
df_crises_cw <- select(
  df_crises,
  crisis_name = crisname,
  actor_name = actor,
  actor_id = cracid,
  year = systrgyr,
  duration = trgterra,
  outcome = outcom
)
df_crises_cw <- filter(df_crises_cw, year >= 1946 & year <= 1989)
df_crises_cw <- filter(df_crises_cw, actor_name %in% c("USA", "RUS", "UKG"))
df_crises_cw
```

That certainly works fine to give us what we want, but it involved a lot of repetitive typing and retyping of `df_crises_cw <- function_name(df_crises_cw, ...)`.
And that's only with fairly simple subsetting operations.

The [pipe operator]{.concept} in R lets us chain together commands like this much more succinctly.
`x |> function_name(...)` is equivalent to `function_name(x, ...)` in R.

```{r}
x <- 1:10
x

mean(x)
x |> mean()
```

On its own the pipe might seem dumb, like just more typing for the same result.
Weren't we trying to reduce the amount of typing?
The pipe is mainly useful when we are chaining many commands together.

```{.r}
# Chained commands
y <- first_command(x, arg1, arg2)
y <- second_command(y, arg3)
y <- third_command(y, arg4, arg5)
fourth_command(y, arg6)

# Same thing, but piped
x |>
  first_command(arg1, arg2) |>
  second_command(arg3) |>
  third_command(arg4, arg5) |>
  fourth_command(arg6)
```

Let's see the pipe in action in the context of our data cleaning example.

```{r}
df_crises |>
  select(
    crisis_name = crisname,
    actor_name = actor,
    actor_id = cracid,
    year = systrgyr,
    duration = trgterra,
    outcome = outcom
  ) |>
  filter(year >= 1946 & year <= 1989) |>
  filter(actor_name %in% c("USA", "RUS", "UKG"))
```

It might take a bit getting used to, but I personally find it much easier to use the pipe when going through the data cleaning process.
One thing to keep in mind, just like when you run these commands the regular way, they won't change your data frame in place.
You need to explicitly assign the output to a variable name.

```{r}
df_crises_cw <- df_crises |>
  select(
    crisis_name = crisname,
    actor_name = actor,
    actor_id = cracid,
    year = systrgyr,
    duration = trgterra,
    outcome = outcom
  ) |>
  filter(year >= 1946 & year <= 1989) |>
  filter(actor_name %in% c("USA", "RUS", "UKG"))
```

Final note on the pipe.
Until pretty recently, the pipe was `%>%` instead of `|>`.
So you'll see a lot of code on the Internet that uses `%>%`.
Don't worry, it works exactly the same as `|>` (except in some edge cases that won't come up for us).

::: {.callout-note title="In-class exercise"}
Use the pipe to create a data frame called `df_long_crises` with the following specs:

*   Same variables as in my example, except with the numeric crisis ID instead of the crisis name
*   Only observations where the actor was involved in the crisis for 100+ days
*   Exclude observations of Russia from 1990 onward

```{r}
#
# [Write your answer here]
#
```
:::


## Transforming

### Changing variables and making new ones

The `mutate()` function lets you change a column in the dataframe, or create a new column using the values in existing columns.
For example, right now the duration of each crisis is measured in days.
We can add new columns to measure duration in weeks and years instead.
As always, if we want our new columns to persist instead of vanishing into the ether, we need to assign the output to a variable --- either overwriting `df_crises_cw` or creating a new data frame.

```{r}
df_crises_cw <- df_crises_cw |>
  mutate(
    duration_weeks = duration / 7,
    duration_years = duration / 365
  )

df_crises_cw
```

There's a very useful function for mutating called `if_else()`.
You invoke it as `if_else(condition, a, b)`:

*   `condition`: vector of `TRUE` and `FALSE` values
*   `a`: value, or vector of values, to use for entries where `condition` is `TRUE`
*   `b`: value, or vector of values, to use for entries where `condition` is `FALSE`

```{r}
# Simple if_else example
x <- c(1, 2, 3, 4)
y <- c(-100, -200, 300, 400)
if_else(x > y, x, y)
if_else(x > y, "ice cream", "pizza")
```

::: {.callout-note title="In-class exercise"}
Use `mutate()` and `if_else()` together to add another column to `df_crises_cw` called `crisis_length`.
This variable should say `"long"` if the crisis is 100 or more days, and `"short"` otherwise.

```{r}
#
# [Write your answer here]
#
```
:::

The "outcome" variable here is recorded as numbers, which stand for different categories of crisis outcomes.
The [ICB codebook](https://duke.box.com/s/l4glcl5jaipmycs7unzraxkp92w1nh3d) explains which category is associated with each numerical value.

1.  Victory: this country achieved its basic goals.
2.  Compromise: this country partly achieved its basic goals.
3.  Stalemate: there was no major change in the situation.
4.  Defeat: this country did not achieve its basic goals, and instead yielded or surrendered.
5.  Other.

So for example, looking at the rows associated with the Berlin Blockade, we see that the USA and United Kingdom experienced victory, while the Soviet Union was defeated.

```{r}
df_crises_cw |>
  filter(crisis_name == "BERLIN BLOCKADE") |>
  select(actor_name, outcome, everything())
```

We *could* use a sequence of 5 `if_else()` statements to convert the `outcome` variable in terms of category names instead of (hard to remember) numeric identifiers.
But it's easier to use `case_when()`:

```{r}
df_crises_cw <- df_crises_cw |>
  mutate(
    outcome = case_when(
      outcome == 1 ~ "victory",
      outcome == 2 ~ "compromise",
      outcome == 3 ~ "stalemate",
      outcome == 4 ~ "defeat",
      outcome == 5 ~ "other"
    )
  )

df_crises_cw
```

::: {.aside}
There's another function called `case_match()` that would let you do this same thing with even less typing.
Go ahead, look it up, and use it if you like!
But `case_when()` is a bit more flexible, so to avoid confusion I'm only going to use it.
:::

### Grouping and summarizing

The `summarize()` function lets us calculate summaries of columns in the data.
For example, let's find the shortest, longest, and average crisis durations among the USA/UK/USSR during the Cold War.

```{r}
df_crises_cw |>
  summarize(
    shortest = min(duration),
    longest = max(duration),
    average = mean(duration)
  )
```

```{r}
# Seemingly easier way
min(df_crises_cw$duration)
max(df_crises_cw$duration)
mean(df_crises_cw$duration)
```

The real power of `summarize()` comes in when you combine it with `group_by()` to calculate summaries for subcategories of the data.
For example, say we wanted to calculate the shortest, longest, and average crisis duration separately for the USA, UK, and USSR.
That would be tedious to do the "normal" way:

```{r}
# one of nine long expressions you'd have to type out
min(df_crises_cw$duration[df_crises_cw$actor_name == "USA"])
```

`group_by |> summarize` makes this *much* easier.

```{r}
df_crises_cw |>
  group_by(actor_name) |>
  summarize(
    shortest = min(duration),
    longest = max(duration),
    average = mean(duration)
  )
```

::: {.callout-note title="In-class exercise"}
In which year of the Cold War did the USA spend the most total days in crises?
Use `filter()`, `group_by()`, `summarize()`, and `arrange()` together to figure it out.

```{r}
#
# [Write your answer here]
#
```
:::

What if you wanted to count the number of crises involving each country?
There's a special function called `n()` that counts the number of observations within each group.

```{r}
df_crises_cw |>
  group_by(actor_name) |>
  summarize(number = n())
```

You can group on multiple variables at once.
The number of rows in the result will be the number of unique combinations of values across the grouping variables.

```{r}
df_crises_cw |>
  group_by(actor_name, outcome) |>
  summarize(
    number = n(),
    shortest = min(duration),
    longest = max(duration)
  )
```


## Reshaping

To get practice with reshaping and merging data, we're going to bring in a second dataset.
`military.csv`, stored at <https://bkenkel.com/qps1/data/military.csv>, contains data on military spending and force sizes by country from 1816 to 2019.

```{r}
#| message: false
df_military <- read_csv("https://bkenkel.com/qps1/data/military.csv")

df_military
```

The amounts here are in thousands of dollars and people respectively.
For example, looking at the first two rows, in 1816 the USA spent \$3.8 million on the military, which consisted of 17,000 soldiers.

How can we reshape this data so that there's a single row for the USA in 1816, a single row for the USA in 1817, and so on?
As of now the data is "longer" than we want it to be, and we'd like it to be "wider".
Hence we'll use the function `pivot_wider()`.
Here's how we use it.

```{r}
df_military_wide <- df_military |>
  pivot_wider(names_from = mil_indicator, values_from = amount)

df_military_wide
```

Making a data frame "wider" means taking data that's currently stored row by row, and spreading it out across columns instead.
The `names_from` argument tells `pivot_wider()` which column of the original data frame contains the names of the new columns we want to create.
The `values_from` argument tells it which column contains the values that we want to put into each column.

::: {.callout-note title="In-class exercise"}
Go back to our data on the USA, UK, and USSR in Cold War crises.
Use `pivot_wider()` to create a new data frame where each row is a unique crisis name, and there are columns for the USA, UK, and USSR telling that country's outcome from the given crisis.
Were there any crises that ended in victory for both the USA and the USSR?

```{r}
#
# [Write your answer here]
#
```
:::

The opposite of `pivot_wider()` is, naturally enough, `pivot_longer()`.
For example, imagine your raw data had a single row for each country, then a separate column for its military spending each year.

```{r}
df_too_wide <- tibble(
  ccode = c(2, 200, 365),
  stateabb = c("USA", "UKG", "RUS"),
  mil1816 = c(17, 255, 800),
  mil1817 = c(15, 190, 700),
  mil1818 = c(14, 173, 600)
)

df_too_wide
```

To use `pivot_longer()`, we have to tell it (1) the set of columns whose values we want to collapse into a single column, (2) what we want to name the column that stores the column names from the original data, and (3) what we want to name the column that stores the values.

```{r}
df_too_wide |>
  pivot_longer(
    starts_with("mil"),
    names_to = "year",
    values_to = "personnel"
  )
```

FYI: If you wanted to turn the year column there into a proper year, you could `mutate()` it to remove the "mil" text and then convert it to a number.

```{r}
df_too_wide |>
  pivot_longer(
    starts_with("mil"),
    names_to = "year",
    values_to = "personnel"
  ) |>
  mutate(
    year = str_replace(year, "mil", ""),
    year = as.numeric(year)
  )
```

How did I know to use the `str_replace()` function there?
The `stringr` package contains tons of helpful functions for manipulating text in R.
You can see everything it does by googling the documentation for it, or by entering `help(package = "stringr")` at the R console.


## Merging

Data work in political science often involves combining data from multiple sources.
For example, here we have one dataset on country participation in international crises, and another on the size of their militaries.
How can we put these together?

The first thing to do is decide which dataset should be the "base" that we merge other data sources into.
What's appropriate depends on the question you're trying to answer.
For our purposes here, let's imagine we want to know whether crisis winners tend to spend more on their military than crisis losers.
That means we only care about the countries that actually ended up in crises, so we should use the crisis data as our base and merge the military size data into that.

The next thing we need to make sure of is that we have some way to identify the same observation across datasets.
Here we are going to match observations by the numerical "country code" and by year.
First we'll edit the military size data so that the country code indicator has the same name as in `df_crises_cw`.
(We'll also drop the country name variable, since we already have that in the original data.)

```{r}
df_military_wide <- df_military_wide |>
  rename(actor_id = ccode) |>
  select(-stateabb)

df_military_wide
```

Next we'll use `left_join()` to merge the datasets together.
We need to tell this function three things:

*   The data frame to use as our base.
*   The data frame that we want to merge values in from.
*   The column names to match observations by.

```{r}
df_crisis_and_mil <- left_join(
  df_crises_cw,
  df_military_wide,
  by = c("actor_id", "year")
)

df_crisis_and_mil
```

Now we can use `group_by()` and `summarize()` to calculate the average size and spending of the military among crisis winners, crisis losers, and so on.

```{r}
df_crisis_and_mil |>
  group_by(outcome) |>
  summarize(avg_spending = mean(spending),
            avg_personnel = mean(personnel))
```

::: {.callout-note title="In-class exercise"}
Winners have smaller militaries than losers on average.
Does this mean that increasing the size of your military actually hurts your ability to win a crisis?
Why or why not?
How could you dig deeper into the data to better figure out whether this is the case?

>
> [Write your answer here]
>
:::

